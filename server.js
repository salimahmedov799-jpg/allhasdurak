import express from "express";
import cors from "cors";
import fetch from "node-fetch";
import multer from "multer";
import fs from "fs";

const app = express();
const upload = multer({ dest: "uploads/" });

app.use(cors());
app.use(express.json());

const PORT = process.env.PORT || 3000;
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

// =======================
// ðŸ§  ÐŸÐÐœÐ¯Ð¢Ð¬ (Ð¿Ñ€Ð¾ÑÑ‚Ð°Ñ)
// =======================
let MEMORY = [];
const MAX_MEMORY = 6;

// =======================
// âœ… ÐŸÐ ÐžÐ’Ð•Ð ÐšÐ Ð¡Ð•Ð Ð’Ð•Ð Ð
// =======================
app.get("/", (req, res) => {
  res.send("Salim AI server is running âœ…");
});

// =======================
// ðŸ’¬ Ð§ÐÐ¢ (Ð¢Ð•ÐšÐ¡Ð¢ + Ð¤ÐžÐ¢Ðž)
// =======================
app.post("/api/chat", upload.single("image"), async (req, res) => {
  try {
    const userMessage = req.body.message || "";

    if (!userMessage && !req.file) {
      return res.json({ reply: "Ð¡Ð¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ âŒ" });
    }

    let content = [];

    // ===== SYSTEM PROMPT =====
    content.push({
      type: "text",
      text:
        "Ð¢Ñ‹ Salim AI â€” ÑƒÐ¼Ð½Ñ‹Ð¹, ÑÐ¿Ð¾ÐºÐ¾Ð¹Ð½Ñ‹Ð¹ Ð¸ Ð¿Ð¾Ð»ÐµÐ·Ð½Ñ‹Ð¹ Ð˜Ð˜.\n" +
        "ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ.\n" +
        "Ð•ÑÐ»Ð¸ Ð¿Ñ€Ð¾ÑÑÑ‚ ÐºÐ¾Ð´ â€” Ð´Ð°Ð²Ð°Ð¹ ÐºÐ¾Ð´.\n" +
        "ÐžÐ±ÑŠÑÑÐ½ÑÐ¹ ÐºÑ€Ð°Ñ‚ÐºÐ¾ Ð¸ Ð¿Ð¾ Ð´ÐµÐ»Ñƒ.\n"
    });

    // ===== MEMORY =====
    MEMORY.forEach(m => {
      content.push({
        type: "text",
        text: m
      });
    });

    // ===== USER MESSAGE =====
    if (userMessage) {
      content.push({
        type: "text",
        text: userMessage
      });
      MEMORY.push(userMessage);
      MEMORY = MEMORY.slice(-MAX_MEMORY);
    }

    // ===== IMAGE =====
    if (req.file) {
      const imageBase64 = fs.readFileSync(req.file.path, "base64");
      content.push({
        type: "image_url",
        image_url: {
          url: `data:image/jpeg;base64,${imageBase64}`
        }
      });
      fs.unlinkSync(req.file.path);
    }

    const response = await fetch("https://api.openai.com/v1/responses", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: "gpt-4.1-mini",
        input: [
          {
            role: "user",
            content
          }
        ]
      })
    });

    const data = await response.json();

    const answer =
      data?.output_text ||
      data?.output?.[0]?.content?.[0]?.text ||
      "AI Ð½Ðµ Ð´Ð°Ð» Ð¾Ñ‚Ð²ÐµÑ‚Ð° ðŸ˜•";

    MEMORY.push(answer);
    MEMORY = MEMORY.slice(-MAX_MEMORY);

    res.json({ reply: answer });

  } catch (error) {
    console.error(error);
    res.json({ reply: "ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐµÑ€Ð²ÐµÑ€Ð° âŒ" });
  }
});

// =======================
// ðŸ–¼ï¸ Ð“Ð•ÐÐ•Ð ÐÐ¦Ð˜Ð¯ ÐšÐÐ Ð¢Ð˜ÐÐžÐš (ÐÐ• Ð¢Ð ÐžÐ“ÐÐ•Ðœ)
// =======================
app.post("/api/image", async (req, res) => {
  try {
    const { prompt } = req.body;

    if (!prompt) {
      return res.status(400).json({ error: "ÐÐµÑ‚ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÐ¸" });
    }

    const response = await fetch(
      "https://api.openai.com/v1/images/generations",
      {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "Authorization": `Bearer ${OPENAI_API_KEY}`
        },
        body: JSON.stringify({
          model: "gpt-image-1",
          prompt,
          size: "1024x1024"
        })
      }
    );

    const data = await response.json();

    if (!data.data || !data.data[0]?.url) {
      return res.status(500).json({ error: "ÐžÑˆÐ¸Ð±ÐºÐ° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ" });
    }

    res.json({ image: data.data[0].url });

  } catch (error) {
    console.error(error);
    res.status(500).json({ error: "ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐµÑ€Ð²ÐµÑ€Ð° Ð¿Ñ€Ð¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ" });
  }
});

// =======================
app.listen(PORT, () => {
  console.log("ðŸš€ Salim AI server running on port " + PORT);
});
